{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意力机制\n",
    "***\n",
    "***\n",
    "Time: 2020-09-16<br>\n",
    "Author: dsy<br>\n",
    "Notes: 《神经网络与深度学习》\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设输入序列为$X=[x_1,\\cdots,x_N] \\in \\mathbb{R}^{d_1 x N}$，输出序列为$H=[h_1,\\cdots,h_N] \\in \\mathbb{R}^{d_2 x N}$,首先我们可以通过线性变换得到三组向量序列：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q & = W_Q X \\in \\mathbb{R}^{d_3 x N},\\\\\n",
    "K & = W_K X \\in \\mathbb{R}^{d_3 x N},\\\\\n",
    "V & = W_V X \\in \\mathbb{R}^{d_3 x N},\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$Q,K,V$分别为查询向量序列，键向量序列和值向量序列，$W_Q \\in \\mathbb{R}^{d_3 x d1},W_K \\in \\mathbb{R}^{d_3 x d1},W_V \\in \\mathbb{R}^{d_2 x d_1}$分别为可学习的参数矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用公式可以得出输出向量$h_i$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h_i & = att \\Big( (K,V),q_i\\Big) \\\\\n",
    "    & = \\sum_{j=1}^{N} \\alpha_{ij}v_j\\\\\n",
    "    & = \\sum_{j=1}^{N} softmax \\Big(s(k_j,q_i) \\Big)v_j\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "常用的注意力打分函数：\n",
    "$$\\begin{array}{cll}\n",
    "\\text{加性模型} & s(x_i,q) & = v^T \\tanh(W x_i + U q) \\\\\n",
    "\\text{点积模型} & s(x_i,q) & = x_i^Tq \\\\\n",
    "\\text{缩放点积模型} & s(x_i,q) & = \\frac{x_i^T q}{\\sqrt{d}} \\\\\n",
    "\\text{双线性模型} & s(x_i,q) & = x_i^T W q \n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L,N,E,S = 100,200,300,400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiheadAttention = torch.nn.MultiheadAttention(\n",
    "    embed_dim = E\n",
    "    , num_heads=10\n",
    "    , dropout=0.0\n",
    "    , bias=True\n",
    "    , add_bias_kv=False\n",
    "    , add_zero_attn=False\n",
    "    , kdim=None\n",
    "    , vdim=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.rand((L,N,E))\n",
    "\n",
    "key = torch.rand((S,N,E))\n",
    "\n",
    "value = torch.rand((S,N,E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output,attn_output_weights = multiheadAttention(\n",
    "    query\n",
    "    , key\n",
    "    , value\n",
    "    , key_padding_mask=None\n",
    "    , need_weights=True\n",
    "    , attn_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 200, 300])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape # L,N,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 100, 400])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_weights.shape # N,L,S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
