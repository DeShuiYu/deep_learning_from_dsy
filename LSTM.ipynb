{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LSTM`\n",
    "***\n",
    "***\n",
    "Time: 2020-09-14<br>\n",
    "Author: dsy\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTM](./imgs/LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "c_t &= f_t \\odot c_{t-1} + i_t \\odot \\tilde{c_t} \\\\\n",
    "h_t &= \\omicron_t \\odot \\tanh(c_t)\\\\\n",
    "\\tilde{c_t} &= \\tanh(W_c x_t + U_c h_{t-1} + b_c)\\\\\n",
    "i_t &= \\sigma(W_ix_t + U_ih_{t-1}+b_i) \\\\\n",
    "f_t &= \\sigma(W_fx_t + U_fh_{t-1}+b_f) \\\\\n",
    "\\omicron_t &= \\sigma(W_\\omicron x_t+U_\\omicron h_{t-1} + b_\\omicron)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMFromDsy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMFromDsy,self).__init__()\n",
    "        \n",
    "    def wub(self):\n",
    "        W = torch.rand((self.m,self.m),requires_grad=True)\n",
    "        U = torch.rand((self.m,self.m),requires_grad=True)\n",
    "        b = torch.rand((self.m,self.n),requires_grad=True)\n",
    "        return W,U,b\n",
    "    \n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        x 形如:[[1,2,3]]\n",
    "        '''\n",
    "        self.m,self.n = x.shape\n",
    "        \n",
    "        ht = torch.zeros((self.m,self.n))\n",
    "        ct = torch.zeros((self.m,self.n))\n",
    "        \n",
    "        Wi,Ui,bi = self.wub()\n",
    "        Wf,Uf,bf = self.wub()\n",
    "        Wo,Uo,bo = self.wub()\n",
    "        \n",
    "        it = torch.sigmoid(Wi .matmul(x)+Ui.matmul(ht) + bi)\n",
    "        ft = torch.sigmoid(Wf .matmul(x)+Uf.matmul(ht) + bf)\n",
    "        ot = torch.sigmoid(Wo .matmul(x)+Uo.matmul(ht) + bo)\n",
    "        \n",
    "        c_t_hat = torch.tanh(ot.matmul(ct))\n",
    "        ct = ft.matmul(ct) + it.matmul(c_t_hat) \n",
    "        ht = ot.matmul(ct)\n",
    "        \n",
    "        return ct,ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmfd = LSTMFromDsy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>)),\n",
       " (tensor([[0.]], grad_fn=<AddBackward0>),\n",
       "  tensor([[0.]], grad_fn=<MmBackward>))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lstmfd(torch.rand((1,1))) for i in range(100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
