{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RNN`\n",
    "***\n",
    "***\n",
    "Time: 2020-09-13<br>\n",
    "Author: dsy\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{aligned}\n",
    "z_t & = Uh_{t-1} + Wx_t+b \\\\\n",
    "h_t & = f(z_t) \\\\\n",
    "y_t & = Vh_t \\\\\n",
    "x_t \\text{是网络的输入}，h_t \\text{隐藏层状态}，z_t \\text{隐藏层的净输入}，& f(\\cdot) \\text{\n",
    "是非线性激活函数，通常为Logistic函数或者Tanh函数}，U \\text{状态-状态权重矩阵},W \\text{状态-输入权重矩阵},b\\text{为偏置}\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNFromDsy2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNFromDsy2,self).__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        m,n = x.shape\n",
    "        U = torch.rand(1,requires_grad=True)\n",
    "        W = torch.rand(1,requires_grad=True)\n",
    "        b = torch.rand(1,requires_grad=True)\n",
    "        V = torch.rand(1,requires_grad=True)\n",
    "        y = torch.empty((m,n),dtype=torch.float32)\n",
    "        ht = torch.zeros((m,n+1),dtype=torch.float32)\n",
    "        \n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                ht[i][j+1] = torch.sigmoid(V*( U*(ht[i][j]) + W*(x[i][j]) + b))\n",
    "                y[i][j] = V * (ht[i][j+1])\n",
    "        return y,ht[:,1:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6920, -0.7670, -0.5207,  0.9815, -0.0420,  0.1500],\n",
       "        [ 0.3686, -1.4934, -0.1194,  2.0738,  0.1585,  0.3091],\n",
       "        [ 0.5719,  0.4486,  0.1359,  0.3469,  0.8337, -0.0827],\n",
       "        [ 1.9388,  0.6318, -0.4251, -1.2832,  0.9672, -0.0168]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn((4,6))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnfd2 = RNNFromDsy2()\n",
    "y,ht = rnnfd2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5082, 0.5503, 0.5697, 0.6599, 0.6086, 0.6157],\n",
       "        [0.5759, 0.5098, 0.5909, 0.7173, 0.6253, 0.6264],\n",
       "        [0.5885, 0.6315, 0.6168, 0.6279, 0.6564, 0.6059],\n",
       "        [0.6675, 0.6483, 0.5844, 0.5242, 0.6556, 0.6098]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5411, 0.5860, 0.6066, 0.7026, 0.6480, 0.6555],\n",
       "        [0.6132, 0.5428, 0.6292, 0.7637, 0.6658, 0.6670],\n",
       "        [0.6266, 0.6723, 0.6567, 0.6686, 0.6989, 0.6451],\n",
       "        [0.7108, 0.6903, 0.6222, 0.5582, 0.6980, 0.6492]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以前的实现想法\n",
    "class RNNFromDsy(nn.Module):\n",
    "    def __init__(self,hidden_size=10):\n",
    "        super(RNNFromDsy,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.m,self.n = x.shape\n",
    "        ht = torch.zeros((self.batch,self.input_size))\n",
    "        U = torch.empty((self.batch,self.batch),requires_grad=True)\n",
    "        W = torch.empty((self.batch,self.batch),requires_grad=True)\n",
    "        b = torch.empty((self.batch,self.input_size),requires_grad=True)\n",
    "        V = torch.empty((self.batch,self.batch),requires_grad=True)\n",
    "        nn.init.uniform_(U)\n",
    "        nn.init.uniform_(W)\n",
    "        nn.init.uniform_(b)\n",
    "        nn.init.uniform_(V)\n",
    "        for i in range(self.hidden_size):\n",
    "            ht = torch.tanh( U.matmul(ht) + W.matmul( x) + b)\n",
    "        return V.matmul(ht)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
