{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droput\n",
    "***\n",
    "***\n",
    "Time: 2020-09-16<br>\n",
    "Author: dsy\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout函数的实现\n",
    "def dropout(x, level):\n",
    "    if level < 0. or level >= 1: #level是概率值，必须在0~1之间\n",
    "        raise ValueError('Dropout level must be in interval [0, 1].')\n",
    "    retain_prob = 1. - level\n",
    "\n",
    "    # 我们通过binomial函数，生成与x一样的维数向量。binomial函数就像抛硬币一样，我们可以把每个神经元当做抛硬币一样\n",
    "    # 硬币 正面的概率为p，n表示每个神经元试验的次数\n",
    "    # 因为我们每个神经元只需要抛一次就可以了所以n=1，size参数是我们有多少个硬币。\n",
    "    random_tensor = np.random.binomial(n=1, p=retain_prob, size=x.shape) #即将生成一个0、1分布的向量，0表示这个神经元被屏蔽，不工作了，也就是dropout了\n",
    "    \n",
    "#     print(\"random_tensor\",random_tensor)\n",
    "\n",
    "#     x = x * random_tensor\n",
    "# #     print(x)\n",
    "#     x = x / retain_prob\n",
    "\n",
    "    x = x * random_tensor  / retain_prob\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721],\n",
       "       [ 0.97873798,  2.2408932 ],\n",
       "       [ 1.86755799, -0.97727788],\n",
       "       [ 0.95008842, -0.15135721]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randn(4,2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7641,  0.4002],\n",
       "        [ 0.9787,  2.2409],\n",
       "        [ 1.8676, -0.9773],\n",
       "        [ 0.9501, -0.1514]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.from_numpy(X).float()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5281,  0.0000],\n",
       "        [ 0.0000,  4.4818],\n",
       "        [ 3.7351, -0.0000],\n",
       "        [ 0.0000, -0.3027]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.dropout(Y,0.5,training =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.52810469,  0.        ],\n",
       "       [ 1.95747597,  4.4817864 ],\n",
       "       [ 3.73511598, -1.95455576],\n",
       "       [ 0.        , -0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout(X,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**去掉为0的相同位置，其它位置的数是相同的。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
